{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efbe766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63cf6456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# load glove embeddings\n",
    "#\n",
    "embeddings_dict = {}\n",
    "embedding_size=200\n",
    "with open(f\"../data/embeddings/glove.twitter.27B.{embedding_size}d.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "641b127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "FLAGS = re.MULTILINE | re.DOTALL\n",
    "\n",
    "def hashtag(text):\n",
    "    text = text.group()\n",
    "    hashtag_body = text[1:]\n",
    "    if hashtag_body.isupper():\n",
    "        result = \"<hashtag> {} <allcaps>\".format(hashtag_body)\n",
    "    else:\n",
    "        result = \" \".join([\"<hashtag>\"] + re.split(r\"(?=[A-Z])\", hashtag_body, flags=FLAGS))\n",
    "    return result\n",
    "\n",
    "def allcaps(text):\n",
    "    text = text.group()\n",
    "    return text.lower() + \" <allcaps>\"\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    # Different regex parts for smiley faces\n",
    "    eyes = r\"[8:=;]\"\n",
    "    nose = r\"['`\\-]?\"\n",
    "\n",
    "    # function so code less repetitive\n",
    "    def re_sub(pattern, repl):\n",
    "        return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "\n",
    "    text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n",
    "    text = re_sub(r\"/\",\" / \")\n",
    "    text = re_sub(r\"@\\w+\", \"<user>\")\n",
    "    text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
    "    text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "    text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
    "    text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "    text = re_sub(r\"<3\",\"<heart>\")\n",
    "    text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\")\n",
    "    text = re_sub(r\"#\\S+\", hashtag)\n",
    "    text = re_sub(r\"([!?.]){2,}\", r\"\\1 <repeat>\")\n",
    "    text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
    "\n",
    "    ## -- I just don't understand why the Ruby script adds <allcaps> to everything so I limited the selection.\n",
    "    #text = (r\"([^a-z0-9()<>'`\\-]){2,}\", allcaps)\n",
    "    text = re_sub(r\"([A-Z]){2,}\", allcaps)\n",
    "\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    processed = []\n",
    "    lables = []\n",
    "    tweets = pd.read_csv(\"../text_twitter_raw.csv\")\n",
    "    tweets = tweets.sample(1700)\n",
    "    for _,row in tweets.iterrows():\n",
    "        tokens = tokenize(row['text'])\n",
    "        lables.append(row['label'])\n",
    "        processed.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d7c2d40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<user> for my small org, it works amazingly well. has everything to do with configuration. i love the vcs <allcaps> integrations.',\n",
       " '<user> i think so <sadface>',\n",
       " 'suck it kat, you fucking cunt. <hashtag> mkr',\n",
       " \"rt <allcaps> <user> <user> a self appointed vigilante for feminism yet shares an article that proclaims men aren't needed. you dont undeâ€¦\",\n",
       " \"kat that's karma <allcaps> b!tch <allcaps> ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ <hashtag> mkr\",\n",
       " 'rt <allcaps> <user> call me sexist but i get annoyed by women anchors on sportscenter',\n",
       " 'what could you have possibly modeled <hashtag> mkr',\n",
       " '<user> <user> unrelated to highlander.  i also prefer fletch lives over the first for same reason as gb <allcaps> <number>  funnier, bottom line.',\n",
       " '<user> but the truth is that mohammed followers were worthless starving thugs that produced nothing and so wanted the riches of khybar.',\n",
       " \"<user> hi you're rad.\"]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96bdf1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# load english spacy model and add tokenizer special cases for special tokens\n",
    "#\n",
    "from spacy.symbols import ORTH, NORM, POS\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "ignore = [u'<user>',u'<allcaps>',u'<hashtag>',u'<url>',u'<smile>',u'<lolface>',u'<sadface>',u'<neutralface>',u'<heart>',\n",
    "          u'<number>',u'<repeat>',u'<elong>']\n",
    "\n",
    "for i in ignore:\n",
    "    nlp.tokenizer.add_special_case(i,[{ORTH: i,NORM: i}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47ab199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# train test split\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X,test_X,train_y,test_y= train_test_split(processed,lables,test_size=200/1700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2dc6051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#count frequency of each token of train set\n",
    "#\n",
    "\n",
    "DF = {}\n",
    "tokenized = nlp.pipe(train_X)\n",
    "N=0\n",
    "for tweet in tokenized:\n",
    "    for w in tweet:\n",
    "        try:\n",
    "            DF[w.text].add(N)\n",
    "        except:\n",
    "            DF[w.text] = {N}\n",
    "    N+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3058e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter    \n",
    "#\n",
    "# calculate tf_idf for document token pair\n",
    "#\n",
    "tf_idf_dict = {}\n",
    "tokenized = nlp.pipe(train_X)\n",
    "for tweet in tokenized:\n",
    "    tokens = [t.text for t in tweet]\n",
    "    counter = Counter(tokens)\n",
    "    for token in np.unique(tokens):\n",
    "        tf = counter[token]/(len(DF.keys()))\n",
    "        df = len(DF[token])\n",
    "        idf = np.log(N/(df+1))\n",
    "        tf_idf_dict[tweet.text, token] = tf*idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c09dec74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# 1st approach randomizing embedding vector\n",
    "# tf weighted\n",
    "#\n",
    "# 2nd approach skipping oov\n",
    "#\n",
    "\n",
    "X_train_embedded = []\n",
    "X_test_embedded = []\n",
    "\n",
    "tokenized_train = nlp.pipe(train_X)\n",
    "tokenized_test = nlp.pipe(test_X)\n",
    "\n",
    "for tweet in tokenized_train:\n",
    "    w_sum = 0.0\n",
    "    tfi_sum =0.0\n",
    "    for t in tweet:\n",
    "        if t.text in embeddings_dict:\n",
    "            w_sum+=tf_idf_dict[tweet.text,t.text]*embeddings_dict[t.text]\n",
    "        else:\n",
    "            w_sum+=tf_idf_dict[tweet.text,t.text]*(np.random.rand(embedding_size)-2*np.random.rand(embedding_size))\n",
    "        tfi_sum += tf_idf_dict[tweet.text,t.text]\n",
    "    X_train_embedded.append(w_sum/tfi_sum)\n",
    "\n",
    "for tweet in tokenized_test:\n",
    "    w_sum = 0.0\n",
    "    tfi_sum =0.0\n",
    "    tokens = [t.text for t in tweet]\n",
    "    counter = Counter(tokens)\n",
    "    for t in tweet:\n",
    "        tf = counter[t.text]/(len(DF.keys())+1)\n",
    "        df = len(DF[t.text]) if t.text in DF else 1\n",
    "        idf = np.log(N/(df+1))\n",
    "        tf_idf = tf*idf\n",
    "        if t.text in embeddings_dict:\n",
    "            w_sum+=tf_idf*embeddings_dict[t.text]\n",
    "        else:\n",
    "            w_sum+=tf_idf*(np.random.rand(embedding_size)-2*np.random.rand(embedding_size))\n",
    "        tfi_sum += tf_idf\n",
    "    X_test_embedded.append(w_sum/tfi_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f05d5a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# 1st approach randomizing embedding vector\n",
    "# tf weighted\n",
    "#\n",
    "# 2nd approach skipping oov\n",
    "#\n",
    "\n",
    "X_train_embedded = []\n",
    "X_test_embedded = []\n",
    "\n",
    "tokenized_train = nlp.pipe(train_X)\n",
    "tokenized_test = nlp.pipe(test_X)\n",
    "\n",
    "for tweet in tokenized_train:\n",
    "    summ = 0.0\n",
    "    N=0\n",
    "    for t in tweet:\n",
    "        if t.text in embeddings_dict:\n",
    "            summ+=embeddings_dict[t.text]\n",
    "        else:\n",
    "            summ+=(np.random.rand(embedding_size)-2*np.random.rand(embedding_size))\n",
    "        N += 1\n",
    "    X_train_embedded.append(summ/N)\n",
    "\n",
    "for tweet in tokenized_test:\n",
    "    summ = 0.0\n",
    "    N=0\n",
    "    for t in tweet:\n",
    "        if t.text in embeddings_dict:\n",
    "            summ+=embeddings_dict[t.text]\n",
    "        else:\n",
    "            summ+=(np.random.rand(embedding_size)-2*np.random.rand(embedding_size))\n",
    "        N += 1\n",
    "    X_test_embedded.append(summ/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "04a87d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tweet_embeddings[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "703f1d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "578adfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(class_weight='balanced', kernel='linear')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "#grid search for best parameters\n",
    "#\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "base_y=2\n",
    "base_n=2\n",
    "def score_for_weights(y,n):\n",
    "    clf = SVC(kernel='rbf',class_weight={'y': y,'n':n})\n",
    "    clf.fit(train_X,train_y)\n",
    "    return(clf.score(test_X,test_y))\n",
    "\n",
    "f1_scorer = make_scorer(f1_score, pos_label=\"positive\")\n",
    "\n",
    "weights = []\n",
    "for y_w in range(2,6):\n",
    "    for n_w in range(2,6):\n",
    "        weights.append({'y':y_w,'n':n_w})\n",
    "\n",
    "clf = SVC(kernel='linear',class_weight='balanced')\n",
    "clf.fit(X_train_embedded,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "abb03c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7088607594936709"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(clf.predict(X_test_embedded),test_y,pos_label=\"positive\")\n",
    "#clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6237cba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_y, clf.predict(X_test_embedded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "0d81aea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier:\n",
      "F1: 0.0, accuracy: 0.692\n",
      "SVM (rbf,balance weighted, C=1):\n",
      "F1: 0.6234509056244042 accuracy: 0.7366666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(train_X, train_y)\n",
    "print(\"Dummy classifier:\")\n",
    "print(f\"F1: {f1_scorer(dummy_clf,X_test_embedded,test_y)}, accuracy: {accuracy_score(test_y, dummy_clf.predict(X_test_embedded))}\")\n",
    "\n",
    "print(\"SVM (rbf,balance weighted, C=1):\")\n",
    "print(f\"F1: {f1_scorer(clf,X_test_embedded,test_y)} accuracy: {accuracy_score(test_y,clf.predict(X_test_embedded))}\")\n",
    "\n",
    "f1s.append(f1_scorer(clf,X_test_embedded,test_y))\n",
    "accs.append(accuracy_score(test_y, clf.predict(X_test_embedded)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edc0c7e",
   "metadata": {},
   "source": [
    "## Adding char2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a3b34bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0260109f8426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#from keras.preprocessing import text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mchars2vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/chars2vec/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/chars2vec/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bullying/lib/python3.9/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bullying/lib/python3.9/site-packages/keras/initializers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;31m# from ALL_OBJECTS. We make no guarantees as to whether these objects will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m# using their correct version.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m \u001b[0mpopulate_deserializable_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bullying/lib/python3.9/site-packages/keras/initializers/__init__.py\u001b[0m in \u001b[0;36mpopulate_deserializable_objects\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mv2_objs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mbase_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInitializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     generic_utils.populate_dict_with_module_objects(\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mv2_objs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0minitializers_v2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects'"
     ]
    }
   ],
   "source": [
    "#\n",
    "# adding char2vec representations\n",
    "#\n",
    "#from keras.preprocessing import text\n",
    "import chars2vec\n",
    "\n",
    "\n",
    "c2v_model = chars2vec.load_model('eng_200')\n",
    "\n",
    "#print(c2v_model.vectorize_words(['bla']))\n",
    "\n",
    "c2v_summed=[]\n",
    "for tweet in processed:\n",
    "    \n",
    "    embedded = c2v_model.vectorize_words([w for w in tweet]).mean(axis=0)\n",
    "    c2v_summed.append(embedded)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "9f25c60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2v_glove_emb = [glove + c2v for glove,c2v in zip(tweet_embeddings,c2v_summed)]\n",
    "train_X,test_X,train_y,test_y= train_test_split(tweet_embeddings,lables,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "67c77bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'class_weight': 'balanced', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'kernel':['linear'], 'C':[1],'class_weight':['balanced']}\n",
    "svc = SVC(class_weight='balanced')\n",
    "clf = GridSearchCV(svc, parameters,scoring=f1_scorer)\n",
    "clf.fit(train_X,train_y)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "6f81d675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6561484918793504\n",
      "0.753\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(test_X,test_y))\n",
    "print(accuracy_score(test_y, clf.predict(test_X)))\n",
    "f1s_c2v.append(clf.score(test_X,test_y))\n",
    "accs_c2v.append(accuracy_score(test_y, clf.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "ccb80f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "92667311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove only f1: 0.6439712024681012\n",
      "Glove only acc: 0.7435666666666666\n",
      "Glove+c2v f1: 0.6500983826205389\n",
      "Glove+c2v acc: 0.7495666666666667\n"
     ]
    }
   ],
   "source": [
    "print(f\"Glove only f1: {np.array(f1s).mean()}\")\n",
    "print(f\"Glove only acc: {np.array(accs).mean()}\")\n",
    "print(f\"Glove+c2v f1: {np.array(f1s_c2v).mean()}\")\n",
    "print(f\"Glove+c2v acc: {np.array(accs_c2v).mean()}\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15bd0fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n",
      "(118,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "word_rac = [('muslim', 604), ('islam', 597), ('murder', 192), ('mohamme', 175), ('isis', 159), ('religion', 151), ('woman', 147), ('people', 142), ('prophet', 135), ('quran', 131), ('year', 120), ('jew', 108), ('rape', 98), ('kill', 92), ('war', 92), ('christian', 90), ('lie', 86), ('terrorist', 86), ('say', 85), ('want', 84), ('world', 84), ('slave', 81), ('get', 80), ('make', 80), ('tell', 80), ('know', 72), ('man', 70), ('hate', 69), ('child', 68), ('go', 64), ('follow', 63), ('hatred', 61), ('attack', 60), ('hadith', 58), ('declare', 58), ('humanity', 58), ('time', 57), ('slavery', 56), ('try', 56), ('use', 54), ('see', 53), ('think', 52), ('islamic', 52), ('pedophile', 51), ('never', 47), ('sexist', 45), ('look', 45), ('give', 44), ('stupid', 44), ('israel', 44), ('read', 43), ('idiot', 43), ('behead', 43), ('bigotry', 42), ('right', 42), ('amp', 41), ('force', 41), ('palestinian', 41), ('exterminate', 40), ('non', 40), ('ago', 40), ('live', 39), ('country', 38), ('care', 38), ('state', 38), ('good', 37), ('stop', 37), ('leave', 36), ('exactly', 36), ('call', 35)]\n",
    "word_sex = [('sexist', 954), ('woman', 617), ('girl', 373), ('kat', 350), ('man', 260), ('female', 250), ('call', 242), ('get', 234), ('think', 190), ('make', 157), ('go', 155), ('say', 149), ('know', 148), ('see', 122), ('right', 120), ('want', 119), ('feminist', 112), ('really', 111), ('sport', 105), ('hate', 99), ('amp', 97), ('good', 96), ('well', 96), ('football', 95), ('bitch', 95), ('look', 94), ('need', 92), ('face', 77), ('time', 76), ('fuck', 75), ('never', 74), ('blonde', 74), ('even', 73), ('people', 72), ('take', 72), ('cook', 71), ('watch', 71), ('drive', 70), ('ever', 70), ('thing', 68), ('funny', 67), ('shit', 66), ('guy', 66), ('talk', 65), ('feminism', 64), ('andre', 63), ('play', 62), ('lol', 62), ('way', 61), ('male', 61), ('bad', 60), ('stop', 58), ('pretty', 55), ('mean', 55), ('still', 55), ('nikki', 54), ('work', 53), ('driver', 52), ('come', 51), ('women', 51), ('much', 50), ('dumb', 50), ('tell', 49), ('find', 48), ('stand', 48), ('game', 47), ('actually', 47), ('job', 45), ('suck', 45), ('katie', 45)]\n",
    "lda_dict = {}\n",
    "for w in word_rac+word_sex:\n",
    "    if(w[0] in lda_dict and lda_dict[w[0]]>=w[1]):\n",
    "        pass\n",
    "    else:\n",
    "        lda_dict[w[0]]=w[1]\n",
    "\n",
    "for pos,k in enumerate(lda_dict.keys()):\n",
    "    lda_dict[k]=(lda_dict[k],pos)\n",
    "\n",
    "for tweet in nlp.pipe(processed):\n",
    "    features = np.zeros(len(lda_dict))\n",
    "    for w in tweet:\n",
    "        if(w.lemma_ in lda_dict):\n",
    "            word =  lda_dict[w.lemma_]\n",
    "            features[word[1]]+=word[0]\n",
    "    features=normalize(features.reshape(-1,1))\n",
    "    print(features[:,0].shape)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb402e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
